<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DOCKER on OS/APP HARDCORE</title>
    <link>https://wubigo.com/tags/docker/</link>
    <description>Recent content in DOCKER on OS/APP HARDCORE</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 Nov 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://wubigo.com/tags/docker/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Choosing a CNI Network Provider for Kubernetes</title>
      <link>https://wubigo.com/post/2018-11-22-cninetworkproviderforkubernetes/</link>
      <pubDate>Thu, 22 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://wubigo.com/post/2018-11-22-cninetworkproviderforkubernetes/</guid>
      <description>The Container Network Interface (CNI) is a library definition, and a set of tools under the umbrella of the Cloud Native Computing Foundation project. For more information visit their GitHub project. Kubernetes uses CNI as an interface between network providers and Kubernetes networking.
Why Use CNI Kubernetes default networking provider, kubenet, is a simple network plugin that works with various cloud providers. Kubenet is a very basic network provider, and basic is good, but does not have very many features.</description>
    </item>
    
    <item>
      <title>容器多种方式链接宿主网络</title>
      <link>https://wubigo.com/post/connect-container-to-host-network/</link>
      <pubDate>Tue, 25 Apr 2017 07:10:55 +0800</pubDate>
      
      <guid>https://wubigo.com/post/connect-container-to-host-network/</guid>
      <description>提示： 以下操作是在VirtualBox虚机环境，并做如下配置
 网络  下拉高级设置，在&amp;rdquo;Adapter Type&amp;rdquo;选择PCnet-FAST III&amp;rdquo;, 而不是默认的e1000 (Intel PRO/1000). 另外&amp;rdquo;Promiscuous Mode&amp;rdquo;必须设置为&amp;rdquo;Allow All&amp;rdquo;. 否则通过网桥连接的容器无法工作, 因为虚拟网卡 会过滤掉掉所有带有不同MAC的数据包。
 多网卡  每块网卡都要做上述调整
准备  安装util-linux  sudo apt install util-linux  /etc/network/interface
cat interfaces # interfaces(5) file used by ifup(8) and ifdown(8) auto lo iface lo inet loopback auto enp0s3 iface enp0s3 inet static address 192.168.1.10 netmask 255.255.255.0 gateway 192.168.1.1 dns-nameservers 192.168.1.1 auto enp0s8 iface enp0s8 inet static address 192.168.1.16 netmask 255.</description>
    </item>
    
    <item>
      <title>Docker Alpine</title>
      <link>https://wubigo.com/post/docker-alpine/</link>
      <pubDate>Fri, 31 Mar 2017 15:07:18 +0800</pubDate>
      
      <guid>https://wubigo.com/post/docker-alpine/</guid>
      <description> set date FROM alpine:3.8 RUN apk add --no-cache tzdata &amp;amp;&amp;amp; rm -rf /var/cache/apk/* ENV TZ Asia/Shanghai RUN ln -s /usr/share/zoneinfo/$TZ /etc/localtime &amp;amp;&amp;amp; echo $TZ &amp;gt; /etc/timezone  docker run -it --rm -e TZ=Asia/Shanghai alpine:3.8 ash  创建/etc/localtime
ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime  </description>
    </item>
    
    <item>
      <title>Docker网络</title>
      <link>https://wubigo.com/post/docker_network/</link>
      <pubDate>Thu, 02 Mar 2017 11:10:51 +0800</pubDate>
      
      <guid>https://wubigo.com/post/docker_network/</guid>
      <description> docker默认的网络 桥接网络
Docker网络macvlan 网络macvlan
Docker宿主网络 宿主网络
Docker覆盖网络 宿主端口绑定 绑定方式： -p
绑定形式
 ip:hostPort:containerPort| ip::containerPort | hostPort:containerPort | containerPort
 containerPort必须指定
docker run --rm --name web -p 80:80 -v /home/bigo/site:/usr/share/nginx/html:ro -d nginx:1.14-alpine  docker 会为端口绑定的容器自动启动docker-proxy进程
docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 80 -container-ip 172.17.0.2 -container-port 80  </description>
    </item>
    
    <item>
      <title>Docker网络macvlan</title>
      <link>https://wubigo.com/post/docker_network_macvlan/</link>
      <pubDate>Wed, 01 Mar 2017 10:49:32 +0800</pubDate>
      
      <guid>https://wubigo.com/post/docker_network_macvlan/</guid>
      <description>介绍 Macvlan支持从一个上层物理接口创建子接口，每个子接口有自己独立的MAC和IP地址。 应用程序，容器或虚机可以绑定到子接口，用子接口的IP和物理网络直接通信。
 好处
 现有的很多网络监控设备还不支持虚拟网络设备的监控，Macvlan支持 不需要新建iptable，nat，route单独管理容器网络  不足
 交换机的每个端口上能连接的不同MAC有策略上限 网卡上过多的MAC会影响性能 Macvlan只支持LINUX   准备  需要4.0以上的内核  uname -r 4.15.0-45-generic   加载macvlan模块  sudo modprobe macvlan lsmod | grep macvlan ... macvlan 24576 0 ...   配置网卡为混杂模式     主机 IP     PC 192.168.1.5/24   VM1 192.168.1.10/24   Container1 192.168.1.128/25    MACVLAN四种工作模式  Macvlan VEPA Macvlan Bridge Macvlan Passthru  创建macvlan ip addr show enp0s3 enp0s3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 1000 link/ether 08:00:27:c0:91:4c brd ff:ff:ff:ff:ff:ff inet 192.</description>
    </item>
    
    <item>
      <title>Docker日志</title>
      <link>https://wubigo.com/post/docker-logging/</link>
      <pubDate>Fri, 17 Feb 2017 08:24:25 +0800</pubDate>
      
      <guid>https://wubigo.com/post/docker-logging/</guid>
      <description>Everything a containerized application writes to stdout and stderr is handled and redirected somewhere by a container engine. For example, the Docker container engine redirects those two streams to a logging driver
 The docker logs command is not available for drivers other than json-file and journald.
logging driver To configure the Docker daemon to default to a specific logging driver, set the value of log-driver to the name of the logging driver in the daemon.</description>
    </item>
    
    <item>
      <title>Docker Check Config</title>
      <link>https://wubigo.com/post/docker-check-config/</link>
      <pubDate>Thu, 25 Feb 2016 17:58:37 +0800</pubDate>
      
      <guid>https://wubigo.com/post/docker-check-config/</guid>
      <description>#!/usr/bin/env bash set -e EXITCODE=0 # bits of this were adapted from lxc-checkconfig # see also https://github.com/lxc/lxc/blob/lxc-1.0.2/src/lxc/lxc-checkconfig.in possibleConfigs=( &#39;/proc/config.gz&#39; &amp;quot;/boot/config-$(uname -r)&amp;quot; &amp;quot;/usr/src/linux-$(uname -r)/.config&amp;quot; &#39;/usr/src/linux/.config&#39; ) if [ $# -gt 0 ]; then CONFIG=&amp;quot;$1&amp;quot; else : ${CONFIG:=&amp;quot;${possibleConfigs[0]}&amp;quot;} fi if ! command -v zgrep &amp;amp;&amp;gt; /dev/null; then zgrep() { zcat &amp;quot;$2&amp;quot; | grep &amp;quot;$1&amp;quot; } fi kernelVersion=&amp;quot;$(uname -r)&amp;quot; kernelMajor=&amp;quot;${kernelVersion%%.*}&amp;quot; kernelMinor=&amp;quot;${kernelVersion#$kernelMajor.}&amp;quot; kernelMinor=&amp;quot;${kernelMinor%%.*}&amp;quot; is_set() { zgrep &amp;quot;CONFIG_$1=[y|m]&amp;quot; &amp;quot;$CONFIG&amp;quot; &amp;gt; /dev/null } is_set_in_kernel() { zgrep &amp;quot;CONFIG_$1=y&amp;quot; &amp;quot;$CONFIG&amp;quot; &amp;gt; /dev/null } is_set_as_module() { zgrep &amp;quot;CONFIG_$1=m&amp;quot; &amp;quot;$CONFIG&amp;quot; &amp;gt; /dev/null } color() { local codes=() if [ &amp;quot;$1&amp;quot; = &#39;bold&#39; ]; then codes=( &amp;quot;${codes[@]}&amp;quot; &#39;1&#39; ) shift fi if [ &amp;quot;$#&amp;quot; -gt 0 ]; then local code= case &amp;quot;$1&amp;quot; in # see https://en.</description>
    </item>
    
    <item>
      <title>Docker Notes</title>
      <link>https://wubigo.com/post/docker-notes/</link>
      <pubDate>Mon, 25 Jan 2016 17:11:05 +0800</pubDate>
      
      <guid>https://wubigo.com/post/docker-notes/</guid>
      <description>busybox nslookup  docker proxy /etc/systemd/system/docker.service.d/https-proxy.conf
[Service] Environment=&amp;quot;HTTP_PROXY=http://127.0.0.1:33351/&amp;quot; Environment=&amp;quot;HTTPS_PROXY=http://127.0.0.1:33351/&amp;quot;  sudo systemctl daemon-reload sudo systemctl restart docker systemctl show --property=Environment docker  docker clean up disk space  delete volumes   $ docker volume rm $(docker volume ls -qf dangling=true) $ docker volume ls -qf dangling=true | xargs -r docker volume rm   docker rmi $(docker images --filter &amp;quot;dangling=true&amp;quot; -q --no-trunc) docker rmi $(docker images | grep &amp;quot;none&amp;quot; | awk &#39;/ / { print $3 }&#39;) docker rm $(docker ps -qa --no-trunc --filter &amp;quot;status=exited&amp;quot;)  Caution</description>
    </item>
    
  </channel>
</rss>